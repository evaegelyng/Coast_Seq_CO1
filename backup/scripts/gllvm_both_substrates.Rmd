---
title: "gllvm model both water and sediment samples"
author: "Karoline"
date: "16/3/2023"
output: html_document
---
In this script I want to build an overall, simple gllvm model for both water and sediment samples with the format: 

richness ~ substrate + habitat + season + season*(substrate + habitat)

This script is based on the method in Marcelos script "gllvm_Phylumga_va".

# Load data and create extra variables

First I will read the necessary packages and load the phyloseq object and create extra variables in the sample data of the phyloseq object. 

```{r load packages and phyloeq object, echo=TRUE}
R.Version()
#R version 4.1.1 (2021-08-10)" --> the newest version
memory.limit()
#8083
###load packages
library("phyloseq")
library("ggplot2")
library("vegan")
library("reshape2")
library("plyr")
library("scales")
library("stringr")
library("RColorBrewer")
library("corrplot")
library("gllvm")
library("gclus")

#contains taxonomy table, otu table and metadata sample data for CO1 pident70 data 
#COSQ_rare2 <- readRDS("C:/Users/Karoline/OneDrive/Speciale/G. Databehandling NYT KORREKT data/RDS filer/COSQ_rare2_correct.rds")
COSQ_rare2 <- readRDS("results/COSQ_rare2_correct.rds")
COSQ_rare2 #IndlÃ¦ser phyloseq objekt med KORREKT data
#phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 6183 taxa and 936 samples ]
#sample_data() Sample Data:       [ 936 samples by 7 sample variables ]
#tax_table()   Taxonomy Table:    [ 6183 taxa by 8 taxonomic ranks ]

#check
COSQ_rare2@otu_table[1,c(1:5)] #taxa = rows, colums=samples
COSQ_rare2@tax_table[1,c(1:5)] #taxa = rows, colums = taxonomy


###Create extra variables in sample_data
COSQ_rare2@sam_data$sshc <- paste(COSQ_rare2@sam_data$substrate_type,
                                  COSQ_rare2@sam_data$season,
                                  COSQ_rare2@sam_data$habitat,
                                  COSQ_rare2@sam_data$cluster, sep="_") #ssch = substrate, season, cluster, habitat

COSQ_rare2@sam_data$ssc<-paste(COSQ_rare2@sam_data$substrate_type,
                               COSQ_rare2@sam_data$season, 
                               COSQ_rare2@sam_data$cluster, sep="_") #ssc = substrate, season, cluster

COSQ_rare2@sam_data$stc<-paste(COSQ_rare2@sam_data$substrate_type, 
                               COSQ_rare2@sam_data$cluster, sep="_") #stc = substrate type, cluster

COSQ_rare2@sam_data$snch<-paste(COSQ_rare2@sam_data$season, 
                                COSQ_rare2@sam_data$cluster, 
                                COSQ_rare2@sam_data$habitat,sep="_") #snch = season, cluster, habitat

#remove cluster 2 (only sampled in the first season)
COSQ_rare2_no_c2 <- subset_samples(COSQ_rare2,!cluster==2) 
doi<-data.frame(sample_data(COSQ_rare2_no_c2)) #new sample data without cluster 2

#compare
COSQ_rare2
#phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 6183 taxa and 936 samples ]
#sample_data() Sample Data:       [ 936 samples by 11 sample variables ]
#tax_table()   Taxonomy Table:    [ 6183 taxa by 8 taxonomic ranks ]

COSQ_rare2_no_c2
#phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 6183 taxa and 930 samples ]
#sample_data() Sample Data:       [ 930 samples by 11 sample variables ]
#tax_table()   Taxonomy Table:    [ 6183 taxa by 8 taxonomic ranks ]

#doi<-data.frame(sample_data(COSQ_rare2_no_c2))
#930 obs (samples) 11 varaible (env. variables)

```


Now I import the abiotic data for the water samples and create extra variables.

```{r Impport water data}
#load metadata_water
#Temperature, salinity etc: 
#wat_metadata <- read.delim("C:/Users/Karoline/OneDrive/Speciale/D. Databehandling NYT data/TSV_CSV_TEXT_etc/Tilsendt/wat_metadata.txt")
wat_metadata <- read.delim("results/metadata/wat_metadata.txt")
#View(wat_metadata)

#add new variables from the water data to the doi sample data
doi$Salinity<-wat_metadata$Salinity[match(doi$snch, wat_metadata$snch)]
doi$Temperature<-wat_metadata$Temperature[match(doi$snch, wat_metadata$snch)]
doi$PO4<-wat_metadata$PO4[match(doi$snch, wat_metadata$snch)]
doi$NO3<-wat_metadata$PO4[match(doi$snch, wat_metadata$snch)]
doi$Chlorophyll<-wat_metadata$Chlorophyll[match(doi$snch, wat_metadata$snch)]
for(i in 1:nrow(doi)){doi[i,"PO4"]<-ifelse(doi[i,"PO4"]<=0,0,doi[i,"PO4"])} #checks whether any values in the PO4 column are less than or equal to zero --> if yes it sets the value to zero. Otherwise it leaves the value unchanged.


```

I import the updated version of the sediment data "sed_metadata".

```{r import sediment data}
#sed_metadata <- read.delim("C:/Users/Karoline/OneDrive/Speciale/D. Databehandling NYT data/TSV_CSV_TEXT_etc/Tilsendt/sed_metadata.txt")
sed_metadata <- read.delim("results/metadata/sed_metadata.txt")
#View(sed_metadata)

#calculate mean value of organic content for each sample (snch = season, cluster, habitat == sample)
OC_f_wat <- ddply(sed_metadata, .(snch), summarise, grp.mean=mean(Organic_content))

#Insert the organic content data from the sediment data into doi (sample data total)
#if the substrate type = sediment --> insert organic_content data from sed_metadata into doi sample data
#if substrate_type is water --> insert the mean-value of organic content for the given sample (the values created in OC_f_wat)
doi$Organic_content<-ifelse(doi$substrate_type=="sediment", sed_metadata$Organic_content[match(doi$root, sed_metadata$Sample_ID)], OC_f_wat$grp.mean[match(doi$snch, OC_f_wat$snch)]) 

#round to five decimals
doi$Organic_content<-round(doi$Organic_content, digits=5)

#mean value of total phospor pr sample
TP_f_wat <- ddply(sed_metadata, .(snch), summarise, grp.mean=mean(TP)) #ddply function --> combine results into a dataframe (for subset of a dataframe)

#Insert TP (total phosphor) into the doi data - same procedure as above for the organic content
doi$TP<-ifelse(doi$substrate_type=="sediment", sed_metadata$TP[match(doi$root, sed_metadata$Sample_ID)], TP_f_wat$grp.mean[match(doi$snch, TP_f_wat$snch)])

doi$TP<-round(doi$TP, digits=4)



#Import water content data to the doi sample data
WC_f_wat <- ddply(sed_metadata, .(snch), summarise, grp.mean=mean(Water_content))

doi$Water_content<-ifelse(doi$substrate_type=="sediment", sed_metadata$Water_content[match(doi$root, sed_metadata$Sample_ID)], WC_f_wat$grp.mean[match(doi$snch, WC_f_wat$snch)])

doi$Water_content<-round(doi$Water_content, digits=4)

#Import organic content
IC_f_wat <- ddply(sed_metadata, .(snch), summarise, grp.mean=mean(Inorganic_content))

doi$Inorganic_content<-ifelse(doi$substrate_type=="sediment", sed_metadata$Inorganic_content[match(doi$root, sed_metadata$Sample_ID)], IC_f_wat$grp.mean[match(doi$snch, IC_f_wat$snch)])

doi$Inorganic_content<-round(doi$Inorganic_content, digits=5)

```


Now I remove all OTU's that lack salinity or chlorophyll data

```{r Remove all OTU's that lack sal or chl data}

##Update OTU table
with_NA1<-rownames(doi[is.na(doi$Salinity),]) #0 samples
which(is.na(doi$Chlorophyll))
with_NA2<-rownames(doi[is.na(doi$Chlorophyll),]) #12 samples
newddw<-subset_samples(COSQ_rare2_no_c2, !(root %in% c(with_NA1, with_NA2))) #remove samples with no sal or chl data

newddw
#phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 6183 taxa and 918 samples ]
#sample_data() Sample Data:       [ 918 samples by 11 sample variables ]
#tax_table()   Taxonomy Table:    [ 6183 taxa by 8 taxonomic ranks ]


tudao0 = filter_taxa(newddw, function(x) sum(x) > 0, TRUE) #filter out taxa that lack sal. or ch. data - 930 samples (in COSQ_rare2_no_c2) minus 12samples without data. 
#930-12=918
tudao0
fdt = prune_samples(sample_sums(tudao0)>0,tudao0) #unnecessary 
fdt
#phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 6128 taxa and 918 samples ]
#sample_data() Sample Data:       [ 918 samples by 11 sample variables ]
#tax_table()   Taxonomy Table:    [ 6128 taxa by 8 taxonomic ranks ]
#View(fdt@tax_table)

po_data<-tax_glom(fdt, "phylum") #merging all OTU's in phyla - therefore we now have 42 taxa
po_data
#phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 42 taxa and 918 samples ]
#sample_data() Sample Data:       [ 918 samples by 11 sample variables ]
#tax_table()   Taxonomy Table:    [ 42 taxa by 8 taxonomic ranks ]


```

#Filtering phyla

Now I will filter out low-abundant, low-freq and "rare" phyla

```{r Filter phyla}
#Remove "rare" and low-frequency phyla, using mean total phyla richness, abundance and number of sites present
otuo <- data.frame(otu_table(fdt))
otuo1 <- t(data.frame(otuo, check.names=F)) #transpose table, so columns = taxa instead of samples
taxo<-data.frame(tax_table(fdt), stringsAsFactors=FALSE)
colnames(otuo1)<-taxo$phylum #columns in the OTU , OBS changed Phylum to phylum
do<-data.frame(sample_data(fdt))
clades<-levels(factor(taxo$phylum)) #object with all the different phylas in the taxonomy table
clades
otuo2<-t(data.frame(otuo1, check.names=F)) #transpose otuo, columns are now samples again
tabr<-cbind(taxo, otuo2) 
tabr <- tabr[,-3:-6] #OBS, I remove different row numbers compared to Marcelos script, as taxa have different row numbers in ours 
tabr <- tabr[,-4] #remove score.id column
#kept only the kingdom, phylum and species columns fra taxa kolonnen


ch<-do$root #extraxts the column with the root names from ,OBS changes sample_root to root
z<-expand.grid("root"=ch, stringsAsFactors=FALSE) #returns a data frame with the ch vector in it



for(i in 1:length(clades))
{
  gtr<-subset(tabr, phylum==clades[i]) 
  rich<-colSums(gtr[,-1:-3] != 0) 
  z<-cbind(z, rich) 
  t<-1+i 
  colnames(z)[t]<-clades[i] 
}
rich_asv_both_substrates<-z[,-1] #removes the first column from z, which is "root"

#Saves as table
#write.table(rich_asv_both_substrates,"rich_asv_both_substrates",sep="\t",row.names=F)
```

The rich_asv_both_substrates is a dataframe containing the number of ASV's pr phyla (42 columns) in each samples (918 samples)

Now I calculate the relative abundance of each phyla in each sample. 


```{r Relative abundance}
#Rel_abund (relative abundance)
datarg = transform_sample_counts(po_data, function(x) x/sum(x)) #calculates the relative abundance of reads in each sample - i think it is the reads in each sample pr phylum is divided with the sum of all reads pr sample. In the phyloseq object po_dataF (the input in this code), is where all taxa are aggregated in phylas. The otu table now contains relative abundances in each sample instead of reads pr phylum in each sample.

datarg
#phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 42 taxa and 918 samples ]
#sample_data() Sample Data:       [ 918 samples by 11 sample variables ]
#tax_table()   Taxonomy Table:    [ 42 taxa by 8 taxonomic ranks ]


tax<-data.frame(tax_table(datarg), stringsAsFactors=FALSE)
otu<-otu_table(datarg)
#View(otu) #rows = taxa
#otu<-t(data.frame(otu,check.names=F)) I remove this code from Marcelos script, as rows and columns are already at the right position in our data
tab<-cbind(tax, otu)
rownames(tab)<-tab$phylum 
tab<-tab[,-1:-8] #remove all taxonomy columns
ttab<-t(data.frame(tab, check.names=F)) #transpose - columns are now = phyla
```


Now I filter lowabundant, low freq phyla

```{r Filtering by rich, abund and sites occurring}
#Filtering by rich, abund and sites occurring
pabund<-as.data.frame(cbind(log10(colMeans(ttab)), colnames(ttab)))
colnames(pabund)[2]<-"clades_p"

prich<-as.data.frame(cbind(log10(colMeans(rich_asv_both_substrates)), colnames(rich_asv_both_substrates)))

colnames(prich)[2]<-"clades_p"
trich<-t(rich_asv_both_substrates) #transposes rich_asv
prich$sqrt_sites_occur <-sqrt(rowSums(trich != 0)) 
abund_rich_summary <- as.data.frame(merge(prich, pabund, by="clades_p")) 
colnames(abund_rich_summary)<-c("clades_p","log10_mean_rich","sqrt_sites_occur","log10_mean_rel_abund")
abund_rich_summary$log10_mean_rich<-as.numeric(abund_rich_summary$log10_mean_rich)
abund_rich_summary$log10_mean_rel_abund<-as.numeric(abund_rich_summary$log10_mean_rel_abund) 
abundsorted<-abund_rich_summary[order( abund_rich_summary[,"log10_mean_rel_abund"] ),] 
richsorted<-abund_rich_summary[order( abund_rich_summary[,"log10_mean_rich"] ),] 
sitessorted<-abund_rich_summary[order( abund_rich_summary[,"sqrt_sites_occur"] ),]

#write.table(abundsorted,"abundsorted_both_substrates",sep="\t",row.names=F)

```

#QQ and Box Cox plots
I make qq plots for the transformed data in abundsorted to check whether the residuals are normally distributed:

```{r QQ plots - step added by me}

#Mean rich - looks normally distributed
qqnorm(abundsorted$log10_mean_rich, pch = 1, frame = FALSE, main= "Normal Q-Q plot (log10_mean_rich)")
qqline(abundsorted$log10_mean_rich, col = "steelblue", lwd = 2)

#Mean rel abund - looks normally distributed
qqnorm(abundsorted$log10_mean_rel_abund, pch = 1, frame = FALSE, main= "Normal Q-Q plot (log10_mean_rel_abundance)")
qqline(abundsorted$log10_mean_rel_abund, col = "steelblue", lwd = 2)

#sqrt sites occur - does not look normally distruted
qqnorm(abundsorted$sqrt_sites_occur, pch = 1, frame = FALSE, main= "Normal Q-Q plot (sqrt_sites_occur)")
qqline(abundsorted$sqrt_sites_occur, col = "steelblue", lwd = 2)


#I try to eliminate transformation of sites_occur and do a qqplot

sites_occur <- (abundsorted$sqrt_sites_occur)^2
qqnorm(sites_occur, pch = 1, frame = FALSE, main= "Normal Q-Q plot (sites_occur)")
qqline(sites_occur, col = "steelblue", lwd = 2)


#I try to log-transform to see if it fits better
log10_sites_occur <- log10(sites_occur)
qqnorm(log10_sites_occur, pch = 1, frame = FALSE, main= "Normal Q-Q plot (sites_occur)")
qqline(log10_sites_occur, col = "steelblue", lwd = 2)

```

To find the optimal transformation of the sites_occur variable I create a box-cox plot

```{r box cox of sites occur - step added by me}
library(MASS)


## 1. Box cox for mean_rich
sites_occur <- as.numeric(sites_occur)
hist(sites_occur,xlab="sites occur")

#in order to calculate the optimal value of lambda, you have to compute a linear model with the lm function and pass it into the boxcox function:
bx1 <- boxcox(lm(sites_occur ~ 1))
lambda <- bx1$x[which.max(bx1$y)]
lambda
#0.3434343
#Corresponds to a sqrt-transformation
#thus we keep the sqrt transformation in the abundsorted df
```


#Filtering taxa continued
After the statistical analyses above of which transformation of data is more suitable, I will continue filtering our data for lowabundant taxa

```{r list the lowest abundant/occuring taxa}

list_top15<-c(abundsorted$clades_p[1:15],richsorted$clades_p[1:15],sitessorted$clades_p[1:15])
phy_to_remove<-as.character(unique(list_top15)) #merge the unique taxa names - we have a list of 18 phylas to remove now

po_data1 = subset_taxa(po_data, !(phylum %in% phy_to_remove)) #42-18=24
po_data1
#phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 24 taxa and 918 samples ]
#sample_data() Sample Data:       [ 918 samples by 11 sample variables ]
#tax_table()   Taxonomy Table:    [ 24 taxa by 8 taxonomic ranks ]

#Filter phyla with abundance lower than 10 in at least 10 % of samples
#Add this step to class modelling
po_data2 = filter_taxa(po_data1, function(x) sum(x > 10) > (0.1*length(x)), TRUE)

#Filter the taxa using a variation coef cutoff of 3.0
#po_data3F = filter_taxa(po_data2, function(x) sd(x)/mean(x) > 1.2, TRUE)

tudao1 = filter_taxa(po_data2, function(x) sum(x) > 0, TRUE)
o_data = prune_samples(sample_sums(tudao1)>0,tudao1)

o_data #only 1 extra phylum was filtered out 
#phyloseq-class experiment-level object
#otu_table()   OTU Table:         [ 23 taxa and 918 samples ]
#sample_data() Sample Data:       [ 918 samples by 11 sample variables ]
#tax_table()   Taxonomy Table:    [ 23 taxa by 8 taxonomic ranks ]

#View(o_data@otu_table)

otuo<-data.frame(otu_table(o_data))
otuo_t <- t(data.frame(otuo, check.names=F)) #I added this code to convert our otu table to the same format as Marcelos. Rows are samples and columns are taxa (phylum)
taxo<-data.frame(tax_table(o_data), stringsAsFactors=FALSE)
colnames(otuo)<-taxo$phylum
ncol(otuo)
do<-data.frame(sample_data(o_data))

#add water variables to sample data
do$Salinity<-doi$Salinity[match(do$snch, doi$snch)]
do$PO4<-doi$PO4[match(do$snch, doi$snch)]
do$Temperature<-doi$Temperature[match(do$snch, doi$snch)]
do$Chlorophyll<-doi$Chlorophyll[match(do$snch, doi$snch)]

#add sediment variables to sample data
do$Organic_content<-doi$Organic_content[match(do$root, doi$root)]
do$TP<-doi$TP[match(do$root, doi$root)]
do$Water_content<-doi$Water_content[match(do$root, doi$root)]
do$Inorganic_content<-doi$Inorganic_content[match(do$root, doi$root)]

#other variables as factor or character
do$habitat <- factor(do$habitat, levels = c("sand", "rocks", "eelgrass"))
do$season <- factor(do$season, levels = c("spring", "autumn"))
do$cluster<-as.character(do$cluster)

#scale/normalize numeric variables (salinity, PO4, Temperature, Chlorophyll, Organic content, TP, Water_content, Inorganic_content) - from column 12-18

do[,12:18]<-scale(do[,12:18])

```

#Create dummy variables

```{r Making dummy variables}

#Mk dummy variables
head(do)
do$season<-as.character(do$season)
do$substrate_type<-as.character(do$substrate_type)

for (h in 1:nrow(do))
{
if(do[h,"season"]=="spring") {
do[h,"season"]<-as.numeric(0)
} else {
do[h,"season"]<-as.numeric(1)}

if(do[h,"substrate_type"]=="sediment") {
do[h,"substrate_type"]<-as.numeric(0)
} else {
do[h,"substrate_type"]<-as.numeric(1)}

if(do[h,"habitat"]=="rocks") {
do[h,"habitat_rocks"]<-as.numeric(1)
} else {
do[h,"habitat_rocks"]<-as.numeric(0)}

if(do[h,"habitat"]=="eelgrass") {
do[h,"habitat_eel"]<-as.numeric(1)
} else {
do[h,"habitat_eel"]<-as.numeric(0)}

}

#autumn = 1, spring = 0
#habitat_rocks = 1 if there is 

do$season<-as.numeric(do$season)
do$substrate_type<-as.numeric(do$substrate_type)



#### NÃET TIL LINJE 240 I MARCELOS SCRIPT gllvm_Phylumga_va


#What is this for? 
# I commented this out as this step is not consistent with the method used in marcelos script for water gllvm models:

#install.packages("zCompositions")
#library(zCompositions)

#otuon0<-cmultRepl(otuo, output = "p-counts",z.warning )This function implements methods for imputing zeros in compositional count data sets based on a Bayesian-multiplicative replacement.


#pr <- propr(counts = otuon0, metric = "rho", ivar = "clr")The PROPER( ) function converts the first character in string, and any subsequent character preceded by a blank, to uppercase.


#trans_otuo<-as.data.frame(pr@logratio)


```

Now I will include date as row effect to consider the temporal bias in sampling.

```{r create a numeric date variable}

#import date to the do sample data
do$Time<-wat_metadata$Time[match(do$snch, wat_metadata$snch)]

#convert dates to numeric values to the number of days after"31-12-18"
reference_date <- as.Date("31-12-18",format = "%d-%m-%y")
do$dates <- as.Date(do$Time,format = "%d-%m-%y")
do$days_since_reference_date <- as.numeric(do$dates-reference_date)

do$days_since_reference_date <- as.numeric(do$days_since_reference_date)
#check that the 1st of jan has no. 1
jan1 <- as.Date("01-01-19",format = "%d-%m-%y")
as.numeric(jan1-reference_date)
#1



```

#New rich_asv object - step added by me
I added this step to the script, from Marcelos water data gllvm script. If I do not create a new rich_asv object as in the script for water samples, R cannot run the gllvm models below --> it will crash.

However, after I added this step and created a new rich_asv object based on the o_data, which has been pruned and filtered for low abundant taxa. The other rich_asv object above is based on the fdt phyloseq object which has not been pruned and filtered - therefore R crashes when I try the create gllvm models based on that object.


```{r New rich_asv object - step added by me}

#getwd() #"C:/Users/Karoline/OneDrive/Speciale/G. Databehandling NYT KORREKT data/R_scripts_new_correct_data"

clades<-levels(factor(taxo$phylum)) #creates a new clades object with the names of all phylas in the new taxo df (from o_data phyloseq object). There are 23 phyla in clades.
otuo2<-t(data.frame(otuo_t, check.names=F)) #transposes otuo_t, now taxa = rows again
tabr<-cbind(taxo, otuo2) #binds the new taxo and the new otuo, OBS the code is the same as above, but the new taxo and otuo2 objects are based on the o_data phyloseq object instead of the fdt phyloseq objec

tabr<-tabr[,-1] #remove kingdom
tabr<-tabr[,-2:-7] #remove all taxonomy except phylum
ch<-do$root #creates a vector containing all 918 sample names
z<-expand.grid("root"=ch, stringsAsFactors=FALSE) #creates a dataframe of ch


for(i in 1:length(clades)) #clades contains all the 23 phyla names also present in tabr (in the phylum column), length=23
{
  gtr<-subset(tabr, phylum==clades[i]) #finds all the phylum names from clades (one at a time) in the tabr dataframe
  rich<-colSums(gtr[,-1] != 0) #sums the no. of reads in all sample for each phylum - removes column 1 = phylum name. Removes all samples phyla with a sample sum of 0?
  z<-cbind(z, rich) #binds the z vector containing the phylum names, and the rich df containg the sum of reads pr sample
  t<-1+i #what is this for? t=24 - maybe for inserting the right column names (one at the time) in the code below
  colnames(z)[t]<-clades[i] #inserts the phylum names from the clades object as column names in the z dataframe
}

rich_asv<-z[,-1]
```


# Find the suitable distrubition (poisson or NB) for my GLLVM models
First I will try to run my model with a poisson distribution.

```{r Test poisson models}

#update.packages("gllvm")
#library(gllvm)

#check the memory limit
#memory.limit()
#8083 GB

#I try to increase memory limit
#memory.limit(size=30000)

#poisson model without explanatory variables
fit_p <- gllvm(rich_asv,num.lv = 2,
                 family = poisson(), 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_p
#log-likelihood:  -19168.71 
#Residual degrees of freedom:  21046 
#AIC:  38473.41 
#AICc:  38473.86 
#BIC:  38801.32 

#Poisson without interactions and without row.eff
fit_p1 <- gllvm(rich_asv,do, num.lv = 2,
                 formula = ~ Temperature + Salinity + substrate_type + habitat_eel + habitat_rocks,
                 family = poisson(), 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_p1
#log-likelihood:  -19452.68 
#Residual degrees of freedom:  20931 
#AIC:  39271.37 
#AICc:  39274.59 
#BIC:  40153.83 

#Can run this code
#WHY DOES THE AIC VALUE INCREASE WHEN I INCLUDE ENVIRONMENTAL PARAMETERS

#same as above but with row.effects included
#fit_p2 <- gllvm(rich_asv,do, num.lv = 2,
#                 formula = ~ Temperature + Salinity + substrate_type + habitat_eel + habitat_rocks,
#                 row.eff = ~ (1 | cluster) + (1 | season) + struc(1 | days_since_reference_date), 
#                 family = poisson(), 
#                 method = "VA", 
#                 control.start = list(starting.val ="zero"))

fit_p2 <- gllvm(rich_asv,do, num.lv = 2,
                 formula = ~ Temperature + Salinity + substrate_type + habitat_eel + habitat_rocks,
                 row.eff = ~ (1 | cluster), 
                 family = poisson(), 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_p2

#crashes when I run this code!!

#I GET THIS ERROR MESSAGE

#Warning in xtfrm.data.frame(x) : cannot xtfrm data frames
#Algorithm converged to infinity, try other starting values or different method. 
#Warning messages:
#1: In gllvm.TMB(y, X = X, lv.X = lv.X, formula = formula, lv.formula = lv.formula,  :
 # Error in optim(objr$par, objr$fn, objr$gr, method = "BFGS", control = list(reltol = reltol,  #: 
#  initial value in 'vmmin' is not finite

#2: In gllvm(rich_asv, do, num.lv = 2, formula = ~Temperature + Salinity +  :
 # Algorithm converged to infinity, try other starting values or different method.


#Poisson model with interactions
#The * is used to specify interactions in the model formula 
# For example: y ~ x * z will include both the main effects of x and z, as well as their interaction term (x:z)

fit_p3 <- gllvm(rich_asv,do, num.lv = 2,
                 formula = ~ Temperature * Salinity * substrate_type * habitat_eel * habitat_rocks,
                 row.eff = ~ (1 | cluster) + (1 | season) + struc(1 | days_since_reference_date), 
                 family = poisson(), 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_p3


#Alternative way to write the interaktion model
#Poisson with interactions
fit_p4 <- gllvm(rich_asv_both_substrates,do, num.lv = 2,
                 formula = ~ Temperature + Salinity + substrate_type + habitat_eel + habitat_rocks + Temperature*(Salinity+substrate_type+habitat_eel+habitat_rocks) + Salinity*(substrate_type+habitat_eel+habitat_rocks)+substrate_type*(habitat_eel+habitat_rocks),
                 row.eff = ~ (1 | cluster) + (1 | season) + struc(1 | days_since_reference_date), 
                 family = poisson(), 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_p4

```



Now I will run the same codes as above but with a negative binomial distribution defined in the "family" argument. I will check which distribution is more suitable by comparing AIC values. 

```{r Test negative binomial distributions}

#NB model without explanatory variables
fit_NB <- gllvm(rich_asv,num.lv = 2,
                 family = "negative.binomial", 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_NB
#log-likelihood:  -19168.71 
#Residual degrees of freedom:  21046 
#AIC:  38473.41 
#AICc:  38473.86 
#BIC:  38801.32 

#Poisson without interactions and without row.eff
fit_NB1 <- gllvm(rich_asv,do, num.lv = 2,
                 formula = ~ Temperature + Salinity + substrate_type + habitat_eel + habitat_rocks,
                 family = "negative.binomial", 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_NB1
#log-likelihood:  -19452.68 
#Residual degrees of freedom:  20931 
#AIC:  39271.37 
#AICc:  39274.59 
#BIC:  40153.83 

#Can run this code
#WHY DOES THE AIC VALUE INCREASE WHEN I INCLUDE ENVIRONMENTAL PARAMETERS

#same as above but with row.effects included
fit_NB2 <- gllvm(rich_asv,do, num.lv = 2,
                 formula = ~ Temperature + Salinity + substrate_type + habitat_eel + habitat_rocks,
                 row.eff = ~ (1 | cluster) + (1 | season) + struc(1 | days_since_reference_date), 
                 family = "negative.binomial", 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_NB2


#Interaction model
fit_NB3 <- gllvm(rich_asv,do, num.lv = 2,
                 formula = ~ Temperature * Salinity * substrate_type * habitat_eel * habitat_rocks,
                 row.eff = ~ (1 | cluster) + (1 | season) + struc(1 | days_since_reference_date), 
                 family = "negative.binomial", 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_NB3


#Alternative way to write the interaktion model
#Poisson with interactions
fit_NB4 <- gllvm(rich_asv_both_substrates,do, num.lv = 2,
                 formula = ~ Temperature + Salinity + substrate_type + habitat_eel + habitat_rocks + Temperature*(Salinity+substrate_type+habitat_eel+habitat_rocks) + Salinity*(substrate_type+habitat_eel+habitat_rocks)+substrate_type*(habitat_eel+habitat_rocks),
                 row.eff = ~ (1 | cluster) + (1 | season) + struc(1 | days_since_reference_date), 
                 family = "negative.binomial", 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))

fit_NB4
```


#Test the optimal number of latent variables

Now I run the for loop below to check which number of latent variables gives the best model (lowest AIC)

```{r Find the optimal number of latent variables}


#poisson model
for(i in 1:5){
  fiti <- gllvm(rich_asv,do, num.lv = 2,
                 formula = ~ Temperature + Salinity + substrate_type + habitat_eel + habitat_rocks,
                 row.eff = ~ (1 | cluster) + (1 | season) + struc(1 | days_since_reference_date), 
                 family = poisson(), 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))
  criteria[i] <- summary(fiti)$AIC
  names(criteria)[i] = i
}

criteria_P

#NB model
for(i in 1:5){
  fiti <- gllvm(rich_asv,do, num.lv = 2,
                 formula = ~ Temperature + Salinity + substrate_type + habitat_eel + habitat_rocks,
                 row.eff = ~ (1 | cluster) + (1 | season) + struc(1 | days_since_reference_date), 
                 family = "negative.binomial", 
                 method = "VA", 
                 control.start = list(starting.val ="zero"))
  criteria[i] <- summary(fiti)$AIC
  names(criteria)[i] = i
}

criteria_NB


```

